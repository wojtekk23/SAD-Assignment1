---
title: "Zadanie zaliczeniowe 1"
author: "Wojciech Kłopotek"
date: "29 04 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Treść zadania

**Celem** zadania jest staystyczna analiza danych znajdujących się w pliku `people.tab`.

**Dane:** Są to dane symulowane; opisują wiek (zmienna `age`), wagę (`weight`), wzrost (`height`), płeć (`gender`), stan cywilny (`married`), liczbę dzieci (`number_of_kids`), posiadane zwierzę domowe (`pet`) oraz miesięczne wydatki (`expenses`) pewnych osób. We wszystkich zadaniach poniżej zmienna `expenses` jest **zmienną objaśnianą** (zależną), a pozostałe zmienne są **zmiennymi objaśniającymi** (niezależnymi).

**Wynikiem** ma być raport w formacie .Rmd oraz skompilowany do html. Raport w obydwu formatach należy przesłać na adres email do prwoadzącego laboratorium do sprawdzenia.

# Zadanie 1

*Wczytaj dane, objerzyj je i podsumuj w dwóch-trzech zdaniach. Pytania pomocnicze: ile jest obserwacji, ile zmiennych ilościowych, a ile jakościowych? Czy są zależności w zmiennych objaśniających (policz i zaprezentuj na wykresach korelacje pomiędzy zmiennymi ilościowymi), a także zbadaj zależność zmiennych jakościowych. Skomentuj wyniki. Czy występują jakieś braki danych?*

```{r}
df <- read.csv("people.tab", sep="\t")
```

Zbiór danych zawiera `r nrow(df)` obserwacji, 3 zmienne jakościowe i 5 zmiennych ilościowych.

```{r}
library(ggplot2)
library(GGally)

ggpairs(df, aes(col=gender), columns = c(1,2,3,6,8))
```


Widzimy statystycznie znaczące korelacje między zmiennymi `expenses` i `age` (wydatkami a wiekiem) oraz `height` i `weight` (wzrostem i wagą) dla zagregowanych danych oraz dla wszystkich płci osobno.

```{r}
ggpairs(df[,c(4,5,7)])
```

Z powyższego wynika między innymi, że osoby będące w związku małżeńskim mają średnio mniej zwierząt od osób nie żyjących w małżeństwach.

W danych występują pojedyncze braki:
```{r}
colSums(is.na(df))
```

Konkretnie zbiór danych zawiera `r length(which(rowSums(is.na(df)) > 0))` wybrakowanych wierszy. Usunę je

```{r}
df = df[-which(rowSums(is.na(df)) > 0),]
```

# Zadanie 2

***Podsumuj dane przynajmniej trzema różnymi wykresami**. Należy przygotować:*

* *wykres typu scatter-plot (taki jak na wykładzie 6, slajd 3) dla wszystkich zmiennych objaśniających ilościowych i zmiennej objaśnianej*
* *Wykresy typu pudełkowy (boxplot) dla jednej wybranej zmiennej ilościowej.*
* *Wykres typu słupkowy (barplot) dla jednej wybranej zmiennej jakościowej.*

*Mile widziane dodatkowe wykresy wg własnej inwencji (np. histogram, punktowy, liniowy, mapa ciepła, ...)*

## Wykres typu scatter-plot

```{r}
pairs(~ age + weight + height + number_of_kids + expenses, data = df, col = 'blue', pch='.')
```

## Wykres typu box-plot dla zmiennej ilościowej

Wykres przybliżający rozkład wieku.

```{r}
library(ggplot2)

ggplot(df) + geom_boxplot(aes(y = age)) + labs(y="Wiek")
```

## Wykres typu słupkowy dla zmiennej jakościowej

Wykres przedstawiający liczby poszczególnych zwierząt

```{r}
# Usuwamy niepoprawny wiersz
ggplot(df) + geom_bar(aes(x = pet)) + labs(x="zwierzęta", y="liczba")
```

## Mapa ciepła

Mapa ciepła pokazująca zależność wydatków w zależności od wzrostu i wagi

```{r}
by_stop = 0.15
weight_cuts <- cut(df$weight, quantile(df$weight, probs=seq(0, 1, 0.1)))
height_cuts <- cut(df$height, quantile(df$height, probs=seq(0, 1, by_stop)))
wh.grid <- expand.grid(X=levels(weight_cuts), Y=levels(height_cuts))

wh.grid$Z <- apply(wh.grid, 1, function(col) mean(df$expenses[which(weight_cuts == col[1] & height_cuts == col[2])]))
ggplot(wh.grid, aes(x=X, y=Y, fill=Z)) + geom_tile() + xlab("Waga") + ylab("Wzrost") + labs(fill="Wydatki")
```

# Zadanie 3

***Policz p-wartości dla hipotez o wartości średniej $m = 170$ i medianie $me = 165$ (cm)** dla zmiennej $wzrost$. Wybierz statystykę testową dla alternatywy lewostronnej, podaj założenia, z jakich korzystałeś i skomentuj, czy wydają Ci się uprawnione*

Założę, że średnia zmiennej $wzrost$ ma rozkład normalny, ze względu na to, że jest duża liczba obserwacji (`r nrow(df)` > 30), są one niezależne i pochodzą one z tego samego rozkładu, więc możemy użyć Centralnego Twierdzenia Granicznego. Ze względu na to, że nie znamy wariancji populacji, ale liczność próby jest liczna ($n = $`r nrow(df)`) użyję wariancji próby i policzę statystykę testową dla standardowego rozkładu normalnego:

$$
Z = \frac{\bar{X} - m}{S_n}\sqrt{n} \sim U
$$

```{r}
m <- 170
n <- nrow(df)
S_n <- sd(df$height)
Z <- (mean(df$height) - m) / S_n * sqrt(n)
pnorm(Z)
```
Jeśli założymy, że $wzrost$ ma rozkład normalny, możemy skorzystać z testu istotności dla średniej przy nieznanej wariancji i wtedy $Z = \frac{\bar{X}-m}{S_n}\sqrt{n-1} \sim T$, gdzie tym razem $S_n$ to obciążony estymator odchylenia standardowego. Wartość p wychodzi niewiele większa.

```{r}
m <- 170
n <- nrow(df)
# Musimy użyć obciążonego estymatora odchylenia standardowego
S_n <- sqrt((n-1)/n)*sd(df$height)
Z <- (mean(df$height) - m) / S_n * sqrt(n-1)
pt(Z, df=n-1)
```


Dla mediany możemy przeprowadzić test Wilcoxona dla jednej próby

```{r}
wilcox.test(df$height, mu=165, alternative="less")
```

# Zadanie 4
***Policz dwustronne przedziały ufności** na poziomie $0.99$ dla zmiennej $wiek$ dla następujących parametrów rozkładu:*
1. *średnia i odchylenie standardowe*
2. *kwantyle $\frac{1}{4}$, $\frac{2}{4}$ i $\frac{3}{4}$*
*Podaj założenia, z jakich korzystałeś i skomentuj, czy wydają Ci się uprawnione.*

Z wykresu Q-Q plot dla zmiennej $wiek$ wynika, że ma ona rozkład w przybliżeniu normalny. (Wykres jest liniowy)

```{r}
# df.woman <- df$gender == "woman"
# df.man <- df$gender == "man"
qqnorm(df$age); qqline(df$age, col=2)
```


## Przedziały ufności dla średniej

Jeśli $P\left(\frac{\bar{X}-\mu}{S_n}\sqrt{n} \in (\pm z_{0.995})\right) = 0.99$, to: $P\left(\mu \in (\bar{X} \mp \frac{S_n}{\sqrt{n}}z_{0.995})\right) = 0.99$. Korzystamy z Centralnego Twierdzenia Granicznego (jak w poprzednim punkcie, korzystam z nieobciążonego estymatora odchylenia standardowego).

```{r}
n <- nrow(df)
S_n <- sd(df$age)

show(c(mean(df$age) - S_n / sqrt(n) * qnorm(0.995), mean(df$age) + S_n / sqrt(n) * qnorm(0.995)))
```

## Przedziały ufności dla odchylenia standardowego

Zakładając, że obserwacje wieku są niezależne, możemy zauważyć, że $P \left( \frac{nS_n^2}{\sigma^2} \in (\chi^2(0.005,n-1), \chi^2(0.995,n-1))\right) = 0.99$, więc: $P \left( \sigma^2 \in \left( \frac{nS_n^2}{\chi^2(0.995,n-1)}, \frac{nS_n^2}{\chi^2(0.005,n-1)} \right) \right) = 0.99$

```{r}
n <- nrow(df)
S2 <- (n-1) / n * var(df$age)

show(c( sqrt(n*S2 / qchisq(0.995, n-1)), sqrt(n*S2 / qchisq(0.005, n-1)) ))
```

## Kwartyle

Aby oszacować przedziały ufności poszczególnych kwantyli, wykorzystam metodę Bootstrap. Wezmę $B=1000$ repróbek.

```{r}
quartile.first <- replicate(1000, quantile(sample(df$age, 500, rep=T), 0.25))
quartile.second <- replicate(1000, quantile(sample(df$age, 500, rep=T), 0.5))
quartile.third <- replicate(1000, quantile(sample(df$age, 500, rep=T), 0.75))
quartiles <- matrix(c(quartile.first, quartile.second, quartile.third), ncol=3)
show(apply(quartiles, 2, mean))
```

Powyżej widzimy średnie kwartyle. Teraz policzmy przedziały ufności:

```{r}
apply(quartiles, 2, function(x) quantile(x, c(0.005, 0.995)))
```

# Zadanie 5

***Przetestuj na poziomie istotności $0.01$ trzy hipotezy istotności:***
1. *różnicy między średnią wartością wybranej zmiennej dla kobiet i dla mężczyzn*
2. *zależności między dwiema zmiennymi ilościowymi*
3. *zależności między dwiema zmiennymi jakościowymi*


## Różnica między średnią wartością wzrostu dla kobiet i dla mężczyzn

```{r}
df.woman <- df$gender == "woman"
df.man <- df$gender == "man"
qqnorm(df[df.woman,]$height); qqline(df[df.woman,]$height, col='red') 
qqnorm(df[df.man,]$height); qqline(df[df.man,]$height, col='red')
```
Wykresy wyglądają na leżące na prostej, więc uznam, że obie zmienne pochodzą z rozkładu normalnego (a przynajmniej tak je przybliżę).

Skorzystamy z t-testu dla dwóch średnich (testu Welcha). Przyjmujemy przy tym hipotezy:
$$
H_0: \mu_1 = \mu_2 \\
H_a: \mu_1 \not= \mu_2
$$
Użyjemy statystyki testowej o rokzładzie
$$
T = \frac{\bar{X_1} - \bar{X_2}}{\sqrt{\frac{s_1^2}{N_1} + \frac{s_2^2}{N_2}}}
$$

```{r}
t.test(df[df.woman,]$height, df[df.man,]$height, alternative="two.sided", var.equal=F, conf.level=0.99)
```
Z powyższego wynika, że dla przyjętego poziomu istotności nie możemy odrzucić hipotezy zerowej, więc przyjmujemy, że kobiety i mężczyźni mają średnio tyle samo wzrostu.

## Zależność między wzrostem a wagą

Za pomocą testu niezależności $\rho$-Spearmana, czy wzrost i waga są niezależne. Hipotezy:
$$
H_0: height \text{ i } weight \text{ są niezależne} \\
H_1: \text{istnieje zależność między } height \text{ i } weight\\
$$
```{r}
cor.test(df$height, df$weight, method="spearman", conf.level = 0.99)
```

p-wartość w powyższej funkcji została policzona korzystając z wartości rozkładu t. Tak czy siak, wartość p dla naszego modelu jest znacznie mniejsza niż wymagany przez nas poziom istotności, więc odrzucamy hipotezę zerową i mówimy, że istnieje zależność między wzrostem i wagą.

## Zależność między płcią a statusem małżeńskim

Tym razem wykorzystamy test $\chi^2$-Pearsona. Przyjmując oznaczenia brzegowych rozkładów: $P(X=x_i)=p_{i.}, P(Y=y_j)=p_{.j}$ oraz łącznego rozkładu $P(X=x_i,Y=y_j)=p_{ij}$ (gdzie $X$ uznajmy, że jest płcią, $Y$ statusem małżeńskim), badamy następujące hipotezy:
$$
H_0: p_{ij} = p_{i.}p_{.j} \\
H_1: p_{ij} \not= p_{i.}p_{.j} \text{ (zmienne zależne)}
$$
```{r}
test.table <- table(df$gender, df$married)
show(test.table)
```
```{r}
chisq.test(test.table)
```
Widzimy, że uzyskane p-value jest wyższe niż oczekiwany od nas poziom istotności, więc nie odrzucamy hipotezy zerowej i uznajemy, że płeć i status małżeński są niezależne.

## Test zgodności rozkładu wzrostu

```{r}
hist(df$height)
```

Histogram zmiennej ma "cięższy" lewy ogon (Podejrzewam, że ma to związek z tym, że po wieku dojrzewania człowiek niewiele rośnie, a w starości w zasadzie ich wzrost się zmniejsza). Spróbowałem znaleźć parametry rozkładu logarytmicznie normalnego, dla których ten rozkład najbliżej oddaje rozkład wzrostu:

```{r}
library(MASS)
fitted.distr <- fitdistr(df$height, "log-normal")
fitted.distr
```

Przetestuję hipotezę, że zmienna `height` ma rozkład log-normalny o powyższych parametrach. Konkretniej:
$$
H_0: (\mu, \sigma) = (5.118,0.119) \\
H_1: (\mu, \sigma) \not = (5.118, 0.119)
$$

Przeprowadzę test Kołmogorowa

```{r}
ks.test(df$height, "plnorm", mean=5.118, sd=0.119)
```
Jako że p-value ($0.3089$) jest większe od poziomu istotności $\alpha = 0.01$, nie odrzucam hipotezy zerowej. Natomiast należy pamiętać, że m.in. test Kołmogorowa nie działa dobrze dla rozkładów z parametrami estymatowanymi z próby (skoro wybraliśmy najlepsze możliwe dopasowanie, to oczywiście, że p-value będzie duże).

# Zadanie 6

*Oszacuj model regresji liniowej, przyjmując za zmienną zależną ($y$) wydatki domowe (`expenses`) a jako zmienne niezależne ($x$) przyjmując pozostałe zmienne. Rozważ, czy konieczne są transformacje zmiennych lub zmiennej objaśniającej. Podaj RSS, R<sup>2</sup>, p-wartości i oszacowania współczynników w pełnym modelu (w modelu zawierającym wszystkie zmienne). Następnie wybierz jedną zmienną objaśniającą, którą można by z pełnego modelu odrzucić (która najgorzej tłumaczy `expenses`). Aby dokonać wyboru takiej zmiennej, dla każdej ze zmiennych objaśniających sprawdź:*

1. *Jaką ma p-wartość w pełnym modelu?*
2. *O ile zmniejsza się R<sup>2</sup>, gdy usuniemy ją z pełnego modelu?*
3. *O ile zwiększa się RSS, gdy ją usuniemy z pełnego modelu?*

*Opisz wnioski*
*Oszacuj model ze zbiorem zmiennych objaśniających pomniejszonym o wybraną zmienną. Sprawdź, czy w otrzymanym przez Ciebie modelu spełnione są założenia modelu liniowego i przedstaw na wykresach diagnostycznych: wykresie zależności reszt od zmiennej objaśnianej, na wykresie reszt studentyzowanych i na wykresie dźwigni i przedyskutuj, czy są spełnione*

```{r}
model <- lm(expenses ~ ., data = df)
summary(model)
```
Widzimy, że w pełnym modelu $RSS = 213.9$, $R^2 = 0.861$, a wartości p są widoczne powyżej.

Ze względu na wysokie p-values dobrymi kandydatami na zmienną do odrzucenia wydają się być: `weight`, `gender`, `married` i `number_of_kids`.

Najlepszym kandydatem zdaje się być zmienna `married`. Nie dość, że przyjmuje największą p-wartość, to $R^2$ praktycznie się nie zmniejsza (na pewno zmniejsza się najmniej ze wszystkich zmniejszonych modeli) i $RSE$ *zmiejsza* się ($RSS$ zwiększyło się mniej niż liczba stopni swobody).
```{r}
model.no.weight <- lm(expenses ~ . - weight, data = df)
model.no.gender <- lm(expenses ~ . - gender, data = df)
model.no.married <- lm(expenses ~ . - married, data = df)
model.no.number_of_kids <- lm(expenses ~ . - number_of_kids, data = df)
summary(model.no.weight)
summary(model.no.gender)
summary(model.no.married)
summary(model.no.number_of_kids)
```

Zatem przyjmę, że najlepiej odrzucić zmienną `married`. Sprawdzę, czy w modelu `model.no.married` spełnione są założenia regresji liniowej:

* **L**inear trend
* **I**ndependent residuals
* **N**ormally distributed residuals
* **E**qual variance of residuals

## Trend liniowy i niezależność residuów

```{r}
plot(model.no.married, which=1)
```

Z powyższego wykresu wynika, że zależność między wydatkami a zmiennymi objaśniającymi nie jest do końca liniowa. Trudno zatem powiedzieć, że spełnione są założenia modelu liniowego.

Prawdopodobnie z tego powodu widzimy, że błędy nie są od siebie niezależne (różnica między sąsiednimi błędami jest mniejsza niż między błędami wybranymi losowo - autokorelacja).

## Rozkład residuów

```{r}
plot(model.no.married, which=2)
```

Z powyższego wykresu wynika, że residua mają w przybliżeniu rozkład normalny.

## Homoskedatyczność wariancji

```{r}
plot(model.no.married, which=3)
```

Widzimy, że wariancja residuów raczej nie zależy od zmiennej objaśnianej - utrzymuje się na mniej więcej tym samym poziomie (Odchylenia czerwonej lini trendu od prostej może wynikać z małej liczby obserwacji po obu stronach osi X na wykresie).

# Obserwacje odstające

Poniżej widać wykres zależności błędów *standardyzowanych* od dźwigni.

```{r}
plot(model.no.married, which=5)
```

A poniżej znajduje się wykres zależności błędów *studentyzowanych* w zależności od predykcji (Czerwone linie zaznaczają poziom $y=3$ i $y=-3$).

```{r}
plot(model.no.married$fitted.values, studres(model.no.married))
studresd <- studres(model.no.married)
ggplot() + geom_point(aes(x=model.no.married$fitted.values, y=studresd)) + geom_hline(aes(yintercept=3), col='red') + geom_hline(aes(yintercept=-3), col='red') + geom_text(aes(x=model.no.married$fitted.values, y=studresd, label=seq(1, length(model.no.married$fitted.values), by=1))) + ylab("Reszty studentyzowane") + xlab("Dopasowane wartości") + theme_minimal()
```

Widzimy 3 obserwacje odstające (reszty studentyzowane odchylają się od 0 o więcej niż 3): 262, 409, 472.

Na wykładzie za dźwigniowe zostały uznane obserwacje, dla których dźwignia jest większa od $\frac{2(p+1)}{n}$. Sprawdźmy, czy istnieją obserwacje dźwigniowe wg tej definicji.

```{r}
p <- 10
n <- 500
which(hatvalues(model.no.married) > 2*(p+1)/n)
```
Widzimy, że jedyną obserwacją zarówno odstającą jak i dźwigniową jest 409. Możemy zatem zastanowić się nad usunięciem ze zbioru danych obserwacji 262 i 472 (obserwacji odstających, niedźwigniowych).

